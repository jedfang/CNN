{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist=input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=mnist.train.images.reshape(55000,28,28)\n",
    "x=tf.reshape(x,[55000,28,28,1])\n",
    "y=mnist.train.labels.reshape(55000,10,1)\n",
    "y=tf.reshape(y,[55000,10,1])\n",
    "lr=.001\n",
    "batch_size=50\n",
    "n_epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32,[batch_size,784],name=\"image\")\n",
    "Y=tf.placeholder(tf.float32,[batch_size,10],name=\"labels\")\n",
    "W=tf.Variable(tf.random_normal(shape=[784,10]),name=\"weights\")\n",
    "b=tf.Variable(tf.zeros([1,10]),name=\"bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_image=tf.reshape(X,[-1,28,28,1])\n",
    "conv1=tf.layers.conv2d(inputs=X_image,filters=32,kernel_size=[5,5],padding=\"SAME\",activation=tf.nn.relu)\n",
    "pool1=tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "conv2=tf.layers.conv2d(inputs=pool1,filters=64,kernel_size=[5,5],padding=\"SAME\",activation=tf.nn.relu)\n",
    "pool2=tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "print(pool2.shape)\n",
    "pool2_flat=tf.reshape(pool2,[-1,7*7*64])\n",
    "print(pool2_flat.shape)\n",
    "dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "print(dense.shape)\n",
    "logits = tf.layers.dense(inputs=dense, units=10)\n",
    "entropy=tf.nn.softmax_cross_entropy_with_logits(logits=logits,labels=Y)\n",
    "loss=tf.reduce_mean(entropy)\n",
    "optimizer=tf.train.GradientDescentOptimizer(lr).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver=tf.train.Saver()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    writer=tf.summary.FileWriter(\"./graph_log_reg\",sess.graph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_of_batches=int(55000/batch_size)\n",
    "    for i in range(n_epochs):\n",
    "        total_loss=0.0\n",
    "        for j in range(num_of_batches):\n",
    "            X_batch,Y_batch=mnist.train.next_batch(batch_size)\n",
    "            j,l=sess.run([optimizer,loss],feed_dict={X:X_batch,Y:Y_batch})\n",
    "            total_loss+=l\n",
    "        print(total_loss)\n",
    "        print(\"Average loss after %d epoch is %d\"%(i+1,float(total_loss)/float(num_of_batches)))\n",
    "        saved=saver.save(sess,'/home/vishal/cc.ckpt')\n",
    "writer.close()    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
